{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing with Spacy\n",
    "\n",
    "OK we are convinced the better the questions are cleaned, the better the features around Nb common words will be powerful (even if we may have reached a limit)\n",
    "\n",
    "So, now objective is to reduced as much as possible the fields 'uncommon words' (or extend the field 'common word')\n",
    "\n",
    "**Lot of things are possible**\n",
    "\n",
    "### Chirurgical and ad hoc cleaning\n",
    "* remove the ? at end. tons of common words are missed due to that\n",
    "* replace all what's, it's, where's by their long versions what is, it is, where is ...\n",
    "* after that and after that only, replace any punctuation by a blank to get rid of these strange \"\" we have seen\n",
    "\n",
    "### Lemmatization\n",
    "Lemmatization allows to replace all variations of a word/verb by their root word. Example : run, running,runners becomes run\n",
    "\n",
    "### Detection of entities and generalisation\n",
    "Detect persons, locations, organisations, any kind of high level entities and replace them by a place holder\n",
    "\n",
    "Example:\n",
    "Will **Donald Trump** be the next president of USA becomes Will **SOMEONE** be the next president of locations\n",
    "\n",
    "Stemmatisation\n",
    "* based on rules so it is fast\n",
    "* may produce non existent word\n",
    "\n",
    "Lemmatisation\n",
    "* produce true words, easier to visualize and check\n",
    "* *HEAVY*\n",
    "* Spacy does lemmatisation and tons of other stuff at the same cost\n",
    "\n",
    "So, we will use Spacy's lemmatisation\n",
    "\n",
    "Note generalisation may loose some informations and must be managed with caution. But we will use the entities information to build some kind of high semantic feature and hopefully also help to visualize the data set\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:RED\">You will work on experiment spacy_preprocessing </span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>Prepare spacy_preprocessing environment in ../spacy_preprocessing</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small><b><i>Done</i></b><p></p></small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>Untouched input data has been loaded. Training: 404290 lines Challenge: 2345796 lines</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "# Ugly incantation to make our framework working\n",
    "import sys\n",
    "sys.path.insert(0, r'/SAPDevelop/QuoraPairs/BruteForce/Tools')\n",
    "\n",
    "#import all our small tools (paths, cache, print,zip,excel, pandas, progress,..)\n",
    "from Tools.all import *\n",
    "\n",
    "# setup the name of our experiment\n",
    "# it will be used to store every result in a unique place\n",
    "EXPERIMENT='spacy_preprocessing'\n",
    "print_alert('You will work on experiment %s' %EXPERIMENT)\n",
    "\n",
    "prepare_environnement(EXPERIMENT)\n",
    "train_dataframe=load_dataframe(CLEAN_TRAINING_DATA)\n",
    "challenge_dataframe=load_dataframe(CLEAN_CHALLENGE_DATA)\n",
    "print_section('Untouched input data has been loaded. Training: %d lines Challenge: %d lines' % (len(train_dataframe),len(challenge_dataframe)))"
   ]
  },
  {
   "source": [
    "### First step : as usual lowercase everything"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our main tool to add feature\n",
    "# no progress info as we will starts to play on a small sample\n",
    "def add_column_from_columns(dataframe,output_column_name,function):\n",
    "    dataframe[output_column_name]=dataframe.apply(function,axis=1)\n",
    "    return dataframe[output_column_name]\n",
    "\n",
    "def add_column_from_column(dataframe,output_column_name,input_column_name,function):\n",
    "    dataframe[output_column_name]=dataframe[input_column_name].apply(function)\n",
    "    return dataframe[output_column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>Before</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                                                               0\nid                                                                             0\nqid1                                                                           1\nqid2                                                                           2\nquestion1     What is the step by step guide to invest in share market in india?\nquestion2              What is the step by step guide to invest in share market?\nis_duplicate                                                                   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>qid1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>qid2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>question1</th>\n      <td>What is the step by step guide to invest in share market in india?</td>\n    </tr>\n    <tr>\n      <th>question2</th>\n      <td>What is the step by step guide to invest in share market?</td>\n    </tr>\n    <tr>\n      <th>is_duplicate</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>Lower case everything in training: Load or rebuild training_lower</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>!!!!! ../spacy_preprocessing/training_lower.pkl is cached!!!</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small><b><i>Done:training_lower contains 404290 lines in 0.1 s</i></b><p></p></small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>Lower case everything in challenge: Load or rebuild challenge_lower</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>!!!!! ../spacy_preprocessing/challenge_lower.pkl is cached!!!</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small><b><i>Done:challenge_lower contains 2345796 lines in 0.9 s</i></b><p></p></small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<b>After</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                                                               0\nid                                                                             0\nqid1                                                                           1\nqid2                                                                           2\nquestion1     what is the step by step guide to invest in share market in india?\nquestion2              what is the step by step guide to invest in share market?\nis_duplicate                                                                   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>qid1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>qid2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>question1</th>\n      <td>what is the step by step guide to invest in share market in india?</td>\n    </tr>\n    <tr>\n      <th>question2</th>\n      <td>what is the step by step guide to invest in share market?</td>\n    </tr>\n    <tr>\n      <th>is_duplicate</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "def build_all_lower_data(dataframe):\n",
    "    print_info('Lower case question1')\n",
    "    dataframe['question1'] = dataframe['question1'].str.lower()\n",
    "    print_info('Lower case question2')\n",
    "    dataframe['question2'] = dataframe['question2'].str.lower()\n",
    "    return dataframe\n",
    "\n",
    "print_section('Before')\n",
    "display(train_dataframe.head(1).transpose())\n",
    "train_dataframe = load_or_build_dataframe('Lower case everything in training','training_lower',build_all_lower_data,train_dataframe)\n",
    "challenge_dataframe = load_or_build_dataframe('Lower case everything in challenge','challenge_lower',build_all_lower_data,challenge_dataframe)\n",
    "print_section('After')\n",
    "display(train_dataframe.head(1).transpose())"
   ]
  },
  {
   "source": [
    "We will start by exploring our preprocessing on a small dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_train = train_dataframe.sample(20000,random_state=42)\n",
    "small_train = train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "sk_stopwords = set(ENGLISH_STOP_WORDS)\n",
    "all_stop_words = nltk_stopwords | sk_stopwords\n",
    "\n",
    "def preprocess_one_row(q1,q2,stopwords):\n",
    "    q1 = set([w for w in q1.split() if w not in stopwords])\n",
    "    len_q1 = len(q1)\n",
    "    q2 = set([w for w in q2.split() if w not in stopwords])\n",
    "    len_q2 = len(q2)\n",
    "\n",
    "    common = q1&q2\n",
    "    len_common = len(common)\n",
    "\n",
    "    uncommon_q1 = q1-common\n",
    "    len_uncommon_q1 = len(uncommon_q1)\n",
    "\n",
    "    #       0     1           2          3               4      \n",
    "    return common,uncommon_q1,len_common,len_uncommon_q1,len_q1\n",
    "    \n",
    "def initial_preprocess(dataframe):\n",
    "    print_warning('Compute all features in one shot')\n",
    "    add_column_from_columns(dataframe,'temp',lambda r: preprocess_one_row(r.question1,r.question2,all_stop_words))\n",
    "    \n",
    "    print_warning('Extract common words between question1 & question2')\n",
    "    add_column_from_column(dataframe,'common_words','temp',lambda x: x[0])\n",
    "    \n",
    "    print_warning('Extract uncommon words in question1')\n",
    "    add_column_from_column(dataframe,'uncommon_words_question1','temp',lambda x: x[1])\n",
    "\n",
    "    print_warning('Extract Nb common_words between question1 & question2')\n",
    "    add_column_from_column(dataframe,'nb_common_words','temp',lambda x: x[2])\n",
    "\n",
    "    print_warning('Extract Nb words in question1 not in common words')\n",
    "    add_column_from_column(dataframe,'nb_uncommon_words','temp',lambda x: x[3])\n",
    "\n",
    "    print_warning('Extract nb_words_question1')\n",
    "    add_column_from_column(dataframe,'nb_words_question1','temp',lambda x: x[4])\n",
    "    dataframe = dataframe.drop(columns='temp')\n",
    "    return dataframe\n",
    "\n",
    "def sniff_changes(dataframe):\n",
    "    nb_all_common = dataframe['nb_common_words'].sum()\n",
    "    nb_all_uncommon = dataframe['nb_uncommon_words'].sum()\n",
    "    if 'new_nb_common_words' in dataframe and 'new_nb_uncommon_words' in dataframe:\n",
    "        new_nb_all_common = dataframe['new_nb_common_words'].sum()\n",
    "        new_nb_all_uncommon = dataframe['new_nb_uncommon_words'].sum()\n",
    "        print_info( \"New common %.3f %% New uncommon %.3f %%\" % (100.*new_nb_all_common/nb_all_common,100.*new_nb_all_uncommon/nb_all_uncommon))\n",
    "    else:\n",
    "        print_warning('??')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract nb_words_question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   common_words                                               uncommon_words_question1\n0  {share, guide, invest, step}                                                       {india?, market}\n1      {(koh-i-noor), kohinoor}                                                      {story, diamond?}\n2             {internet, speed}                                    {connection, vpn?, using, increase}\n3                            {}                                        {solve, mentally, it?, lonely?}\n4                            {}  {methane, sugar,, oxide?, water, carbon, dissolve, salt,, di, quikly}\n5   {capricorn, say, moon, me?}                                  {astrology:, cap, rising...what, sun}\n6                            {}                                                          {tiago?, buy}\n7                  {geologist?}                                                                 {good}\n8                {use, instead}                                                                {シ, し?}\n9              {hack, motorola}                             {(company):, motorolla, dcx3400?, charter}",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_words</th>\n      <th>uncommon_words_question1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{share, guide, invest, step}</td>\n      <td>{india?, market}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{(koh-i-noor), kohinoor}</td>\n      <td>{story, diamond?}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{internet, speed}</td>\n      <td>{connection, vpn?, using, increase}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{}</td>\n      <td>{solve, mentally, it?, lonely?}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{}</td>\n      <td>{methane, sugar,, oxide?, water, carbon, dissolve, salt,, di, quikly}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{capricorn, say, moon, me?}</td>\n      <td>{astrology:, cap, rising...what, sun}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{}</td>\n      <td>{tiago?, buy}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{geologist?}</td>\n      <td>{good}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{use, instead}</td>\n      <td>{シ, し?}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{hack, motorola}</td>\n      <td>{(company):, motorolla, dcx3400?, charter}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>??</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "\n",
    "small_train = initial_preprocess(small_train)\n",
    "display(small_train[['common_words','uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)\n"
   ]
  },
  {
   "source": [
    "* Remove all these question marks\n",
    "* "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern to easily iterate\n",
    "\n",
    "def preprocess_one_row(q1,q2,stopwords):\n",
    "    q1 = clean_text(q1)\n",
    "    q2 = clean_text(q2)\n",
    "\n",
    "    q1 = set([w for w in q1.split() if w not in stopwords])\n",
    "    len_q1 = len(q1)\n",
    "    q2 = set([w for w in q2.split() if w not in stopwords])\n",
    "    len_q2 = len(q2)\n",
    "\n",
    "    common = q1&q2\n",
    "    len_common = len(common)\n",
    "\n",
    "    uncommon_q1 = q1-common\n",
    "    len_uncommon_q1 = len(uncommon_q1)\n",
    "\n",
    "    #       0     1           2          3               4      \n",
    "    return common,uncommon_q1,len_common,len_uncommon_q1,len_q1\n",
    "\n",
    "def new_preprocess(dataframe):\n",
    "    print_warning('Compute all features in one shot')\n",
    "    add_column_from_columns(dataframe,'temp',lambda r: preprocess_one_row(r.question1,r.question2,all_stop_words))\n",
    "    \n",
    "    print_warning('Extract common words between question1 & question2')\n",
    "    add_column_from_column(dataframe,'new_common_words','temp',lambda x: x[0])\n",
    "    \n",
    "    print_warning('Extract uncommon words in question1')\n",
    "    add_column_from_column(dataframe,'new_uncommon_words_question1','temp',lambda x: x[1])\n",
    "\n",
    "    print_warning('Extract Nb common_words between question1 & question2')\n",
    "    add_column_from_column(dataframe,'new_nb_common_words','temp',lambda x: x[2])\n",
    "\n",
    "    print_warning('Extract Nb words in question1 not in common words')\n",
    "    add_column_from_column(dataframe,'new_nb_uncommon_words','temp',lambda x: x[3])\n",
    "\n",
    "    dataframe = dataframe.drop(columns='temp')\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.329 % New uncommon 88.429 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.364 % New uncommon 88.365 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.678 % New uncommon 87.088 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "\n",
    "    # shortcuts\n",
    "    text = re.sub(\"\\'s\", \" \", text) \n",
    "    text = re.sub(\" whats \", \" what is \", text)\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "    text = re.sub(\"n't\", \" not \", text)\n",
    "    text = re.sub(\"i'm\", \"i am\", text)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text)\n",
    "    text = re.sub(\"e-mail\", \" email \", text)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text)\n",
    "#    text = re.sub(\"\\(s\\)\", \" \", text)\n",
    "#    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
    "#    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.683 % New uncommon 87.086 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub('’', \"'\", text) # special single quote\n",
    "    text = re.sub('`', \"'\", text) # special single quote\n",
    "    text = re.sub('“', \"'\", text) # special double quote\n",
    "    text = re.sub('？', '?', text) \n",
    "    text = re.sub('…', ' ', text) \n",
    "    text = re.sub('é', 'e', text)\n",
    "\n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' ', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.', ' america ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?United State(s)?', ' america ', text)\n",
    "#    text = re.sub('\\(s\\)', ' ', text)\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.687 % New uncommon 87.083 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' ', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.', ' america ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?United State(s)?', ' america ', text)\n",
    "#    text = re.sub('\\(s\\)', ' ', text)\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.702 % New uncommon 87.082 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' ', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.', ' america ', text)\n",
    "    text = re.sub('(the[\\s]+|The[\\s]+)?United State(s)?', ' america ', text)\n",
    "#    text = re.sub('\\(s\\)', ' ', text)\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 111.770 % New uncommon 87.056 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' ', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('\\(s\\)', ' ', text)\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "\n",
    "    # stolen at kaggle : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "\n",
    "    # very weird !!! these ones decrease the hit % WTF ?\n",
    "\n",
    "    #text = re.sub(r\" (the[\\s]+|the[\\s]+)?us(a)? \", \" usa \", text)\n",
    "    #text = re.sub('(the[\\s]+|the[\\s]+)?united state(s)?', ' usa ', text)\n",
    "\n",
    "    text = re.sub(r\" UK \", \" england \", text)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text)\n",
    "    text = re.sub(r\" intially \", \" initially \", text)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text) \n",
    "    text = re.sub(r\" actived \", \" active \", text)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text)\n",
    "    text = re.sub(r\" programing \", \" programming \", text)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text)\n",
    "    text = re.sub(r\" iii \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" bangalore \", text)\n",
    "    text = re.sub(r\" j k \", \" jk \", text)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" jk \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 115.516 % New uncommon 82.359 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' ', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('\\(s\\)', ' ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "\n",
    "    # stolen at kaggle : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "    # very weird !!! these ones decrease the hit % WTF ?\n",
    "\n",
    "    #text = re.sub(r\" (the[\\s]+|the[\\s]+)?us(a)? \", \" usa \", text)\n",
    "    #text = re.sub('(the[\\s]+|the[\\s]+)?united state(s)?', ' usa ', text)\n",
    "\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text)\n",
    "    text = re.sub(r\" intially \", \" initially \", text)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text) \n",
    "    text = re.sub(r\" actived \", \" active \", text)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text)\n",
    "    text = re.sub(r\" programing \", \" programming \", text)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text)\n",
    "    text = re.sub(r\" iii \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" bangalore \", text)\n",
    "    text = re.sub(r\" j k \", \" jk \", text)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" jk \", text)\n",
    "\n",
    "    \n",
    "    # some others\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)    \n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    # Now we can remove punctuation but not all !\n",
    "    # we keep - and @ for later maybe \n",
    "    text = ''.join([c for c in text if c not in '!\"#$%&\\'()*+,./:;<=>?[\\\\]^_`{|}~'])\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 115.516 % New uncommon 82.360 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' is', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    # this one is tricky do it in order\n",
    "    text = re.sub(\"wouldn't\", 'would not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('\\(s\\)', ' ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "\n",
    "    # stolen at kaggle : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "    # very weird !!! these ones decrease the hit % WTF ?\n",
    "\n",
    "    #text = re.sub(r\" (the[\\s]+|the[\\s]+)?us(a)? \", \" usa \", text)\n",
    "    #text = re.sub('(the[\\s]+|the[\\s]+)?united state(s)?', ' usa ', text)\n",
    "\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text)\n",
    "    text = re.sub(r\" intially \", \" initially \", text)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text) \n",
    "    text = re.sub(r\" actived \", \" active \", text)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text)\n",
    "    text = re.sub(r\" programing \", \" programming \", text)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text)\n",
    "    text = re.sub(r\" iii \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" bangalore \", text)\n",
    "    text = re.sub(r\" j k \", \" jk \", text)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" jk \", text)\n",
    "\n",
    "    \n",
    "    # some others\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\"'m \", \" am \", text)\n",
    "\n",
    "    # Now we can remove punctuation but not all !\n",
    "    # we keep - and @ for later maybe \n",
    "    text = ''.join([c for c in text if c not in '!\"#$%&\\'()*+,./:;<=>?[\\\\]^_`{|}~'])\n",
    "\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "source": [
    "I changed my mind\n",
    "\n",
    "Instead of replacing punctuation by nothing, we should surround it with blanks. Otherwise we ar just generating more unknown words\n",
    "\n",
    "Example\n",
    "monday,tuesday i will go swimming.sure! -> MondayTuesday i will go swimmingsure\n",
    "monday,tuesday i will go swimming.sure! -> monday tuesday i will go swimming sure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 118.768 % New uncommon 82.289 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "FINAL_PUNC_CLEANER = str.maketrans(dict([ (c,' ') for c in '!\"#$%&\\'()*+,./:;<=>?[\\\\]^_`{|}~-@']))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    # will generate more ' so do it first\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' is', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    # this one is tricky do it in order\n",
    "    text = re.sub(\"wouldn't\", 'would not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('\\(s\\)', ' ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "\n",
    "    # stolen at kaggle : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "    # very weird !!! these ones decrease the hit % WTF ?\n",
    "\n",
    "    #text = re.sub(r\" (the[\\s]+|the[\\s]+)?us(a)? \", \" usa \", text)\n",
    "    #text = re.sub('(the[\\s]+|the[\\s]+)?united state(s)?', ' usa ', text)\n",
    "\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text)\n",
    "    text = re.sub(r\" intially \", \" initially \", text)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text) \n",
    "    text = re.sub(r\" actived \", \" active \", text)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text)\n",
    "    text = re.sub(r\" programing \", \" programming \", text)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text)\n",
    "    text = re.sub(r\" iii \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" bangalore \", text)\n",
    "    text = re.sub(r\" j k \", \" jk \", text)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" jk \", text)\n",
    "\n",
    "    \n",
    "    # some others\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\"'m \", \" am \", text)\n",
    "\n",
    "    # will blank any of !\"#$%&\\'()*+,./:;<=>?[\\\\]^_`{|}~-@\n",
    "    # Note the @ is dubious : won't we loose some emails\n",
    "    text = text.translate(FINAL_PUNC_CLEANER)\n",
    "\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Compute all features in one shot</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract common words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract uncommon words in question1</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb common_words between question1 & question2</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Extract Nb words in question1 not in common words</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>New common 118.681 % New uncommon 82.213 %</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "# I do special stuff with $ and roupie char\n",
    "FINAL_PUNC_CLEANER = str.maketrans(dict([ (c,' ') for c in '!\"#%&\\'()*+,./:;<=>?[\\\\]^_`{|}~-@']))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('\\?',' ',text) # ?\n",
    "    # odd chars\n",
    "    # will generate more ' so do it first\n",
    "    text = re.sub(\"’\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"`\", \"'\", text) # special single quote\n",
    "    text = re.sub(\"“\", '\"', text) # special double quote\n",
    "    text = re.sub(\"？\", \"?\", text) \n",
    "    text = re.sub(\"…\", \" \", text) \n",
    "    text = re.sub(\"é\", \"e\", text)\n",
    "    \n",
    "    # shortcuts\n",
    "    text = re.sub('\\'s', ' is', text) \n",
    "    text = re.sub(' whats ', ' what is ', text)\n",
    "    text = re.sub('\\'ve', ' have ', text)\n",
    "    text = re.sub(\"can't\", 'can not', text)\n",
    "    # this one is tricky do it in order\n",
    "    text = re.sub(\"wouldn't\", 'would not', text)\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    text = re.sub(\"i'm\", 'i am', text)\n",
    "    text = re.sub('\\'re', ' are ', text)\n",
    "    text = re.sub('\\'d', ' would ', text)\n",
    "    text = re.sub('\\'ll', ' will ', text)\n",
    "    text = re.sub('e\\.g\\.', ' eg ', text)\n",
    "    text = re.sub('b\\.g\\.', ' bg ', text)\n",
    "    text = re.sub('e-mail', ' email ', text)\n",
    "    text = re.sub('\\(s\\)', ' ', text)\n",
    "\n",
    "    # Numbers and measures are a true mess\n",
    "    # 12,000 -> 12000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', '', text)\n",
    "\n",
    "    # Quora is very used in India so roupie (rs) is often present\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text)\n",
    "\n",
    "    # stolen at kaggle : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "\n",
    "#    text = re.sub('[c-fC-F]\\:\\/', ' disk ', text)\n",
    "#    text = re.sub('(\\d+)(kK)', ' \\g<1>000 ', text)\n",
    "    # very weird !!! these ones decrease the hit % WTF ?\n",
    "\n",
    "    #text = re.sub(r\" (the[\\s]+|the[\\s]+)?us(a)? \", \" usa \", text)\n",
    "    #text = re.sub('(the[\\s]+|the[\\s]+)?united state(s)?', ' usa ', text)\n",
    "\n",
    "    text = re.sub(r\" uk \", \" england \", text)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text)\n",
    "    text = re.sub(r\" intially \", \" initially \", text)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text) \n",
    "    text = re.sub(r\" actived \", \" active \", text)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text)\n",
    "    text = re.sub(r\" programing \", \" programming \", text)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text)\n",
    "    text = re.sub(r\" iii \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" bangalore \", text)\n",
    "    text = re.sub(r\" j k \", \" jk \", text)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" jk \", text)\n",
    "\n",
    "    \n",
    "    # some others\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\"'m \", \" am \", text)\n",
    "\n",
    "    # units\n",
    "    text = re.sub(r\"(\\d+)kgs \", lambda m: m.group(1) + ' kg ', text)        # e.g. 4kgs => 4 kg\n",
    "    text = re.sub(r\"(\\d+)kg \", lambda m: m.group(1) + ' kg ', text)         # e.g. 4kg => 4 kg\n",
    "    text = re.sub(r\"(\\d+)k \", lambda m: m.group(1) + '000 ', text)          # e.g. 4k => 4000\n",
    "    text = re.sub(r\"\\$(\\d+)\", lambda m: m.group(1) + ' dollar ', text)\n",
    "    text = re.sub(r\"(\\d+)\\$\", lambda m: m.group(1) + ' dollar ', text)\n",
    "    # This one is important in 2017\n",
    "    text = re.sub(' donald trump',' trump ',text)\n",
    "    text = re.sub(' dollars',' dollar ',text)\n",
    "    text = re.sub(' quaro',' quora ',text)\n",
    "    text = re.sub(r\"googling\", \" google \", text)\n",
    "    text = re.sub(r\"googled\", \" google \", text)\n",
    "    text = re.sub(r\"googleable\", \" google \", text)\n",
    "    text = re.sub(r\"googles\", \" google \", text)\n",
    "    \n",
    "    text = re.sub(r\"₹\", \" rs \", text)      # 测试！\n",
    "    text = re.sub(r\"\\$\", \" dollar \", text)  \n",
    "    \n",
    "    # will blank any of !\"#%&\\'()*+,./:;<=>?[\\\\]^_`{|}~-@\n",
    "    # Note the @ is dubious : won't we loose some emails\n",
    "    # and $ is replaced by dollar before\n",
    "    text = text.translate(FINAL_PUNC_CLEANER)\n",
    "\n",
    "    return text\n",
    "\n",
    "small_train = new_preprocess(small_train)\n",
    "#display(small_train[['common_words','new_common_words','uncommon_words_question1','new_uncommon_words_question1']].head(10))\n",
    "sniff_changes(small_train)"
   ]
  },
  {
   "source": [
    "Question that may have impact next steps\n",
    "How many unicode chars are present ?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=404290.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df79d409fece4a9a95998cb6a8bd3ca4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=404290.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1f55624fec047eaafa224db34838735"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2345796.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3d1b8691a58478aa6dcf1fbb1a98185"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2345796.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ebf0bcda0cf4110a44f91422492d759"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Unicode train: 0.022 challenge: 0.021</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "# Ugly but easy\n",
    "def sniff_unicode(s):\n",
    "    if re.sub('[^\\x00-\\x7F]+', '', s) != s:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "nb_unicode_train = train_dataframe['question1'].progress_apply(sniff_unicode).sum()/len(train_dataframe)\n",
    "nb_unicode_train += train_dataframe['question2'].progress_apply(sniff_unicode).sum()/len(train_dataframe)\n",
    "nb_unicode_challenge = challenge_dataframe['question1'].progress_apply(sniff_unicode).sum()/len(challenge_dataframe)\n",
    "nb_unicode_challenge += challenge_dataframe['question2'].progress_apply(sniff_unicode).sum()/len(challenge_dataframe)\n",
    "print_warning('Unicode train: %.3f challenge: %.3f' %(nb_unicode_train,nb_unicode_challenge))"
   ]
  },
  {
   "source": [
    "Humpf, 0.02% of questions has some words fully in Unicode:\n",
    "* awfully small.\n",
    "* we are pushing the limits of this 'nb common words' feature and every little bit of information matters for the kaggle result\n",
    "\n",
    "* Not clear if it does worth it ...\n",
    "* Not clear also if we just replace it with nothing or with a generic placeholder like 'unicode_text' ...\n",
    "\n",
    "I decide to not go so far (and a quick test showed kaggle score was slightly decreasing)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}