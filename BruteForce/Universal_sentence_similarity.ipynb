{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600196160850",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import os\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from shutil import copyfile\n",
    "from IPython.display import IFrame, display, HTML\n",
    "#tqdm_pandas is needed only for old versions of tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm.autonotebook  import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "# This is supposed to enhance default pandas display\n",
    "pandas.set_option('display.width',200)\n",
    "pandas.set_option('display.max_colwidth',200)\n",
    "\n",
    "# the folder where this experiment will be stored\n",
    "EXPERIMENT = 'universal_sentence_similarity_lite'\n",
    "\n",
    "# The name of the docker image (used to display docker command to copy apply files to windows host)\n",
    "DOCKER_IMAGE_NAME = 'dev_ds_1'\n",
    "\n",
    "# Some common resources\n",
    "PANDAS_STORE = '../PandasStore'\n",
    "KAGGLE_EXE = '/root/anaconda3/bin/kaggle'\n",
    "PICKLE_EXTENSION = '.pkl'\n",
    "CLEAN_TRAINING_DATA = 'clean_training'\n",
    "CLEAN_CHALLENGE_DATA = 'clean_challenge'\n",
    "\n",
    "# Other useful constants\n",
    "ZIP_EXTENSION = '.zip'\n",
    "SEP_IN_FILE_NAME = '!'\n",
    "KAGGLE_GET_SUBMISSIONS_COMMAND = KAGGLE_EXE +' competitions submissions quora-question-pairs --csv'\n",
    "EXCEL_PRECISION='%.6f'\n",
    "\n",
    "# Try to have a minimal decoration in notebook output\n",
    "def print_html(s):\n",
    "    display(HTML(s, metadata=dict(isolated=True)))\n",
    "    \n",
    "def start_small():\n",
    "    display(HTML('<span><small>', metadata=dict(isolated=True)))\n",
    "\n",
    "def print_small(s):\n",
    "    print_html('<small>',s,'</small>')\n",
    "\n",
    "def end_small():\n",
    "    display(HTML('</small></span>', metadata=dict(isolated=True)))\n",
    "\n",
    "def start_italic():\n",
    "    display(HTML('<i>', metadata=dict(isolated=True)))\n",
    "\n",
    "def print_italic(s):\n",
    "    print_html('<i>'+s+'</i>')\n",
    "\n",
    "def end_italic():\n",
    "    display(HTML('</i>', metadata=dict(isolated=True)))\n",
    "\n",
    "def start_bold():\n",
    "    display(HTML('<b>', metadata=dict(isolated=True)))\n",
    "\n",
    "def print_bold(s):\n",
    "    print_html('<b>'+s+'</b>')\n",
    "\n",
    "def end_bold():\n",
    "    display(HTML('</b>', metadata=dict(isolated=True)))\n",
    "\n",
    "def print_bullet(s):\n",
    "    print_html('<li>'+s)\n",
    "\n",
    "def print_section(s):\n",
    "    print_bold(s)\n",
    "    print_html('<HR>')\n",
    "\n",
    "def print_done(s):\n",
    "    print_html('<span style=\"color:LIMEGREEN\"><small><b><i>'+s+'</i></b><p></p></small></span>')\n",
    "\n",
    "def print_info(s):\n",
    "    print_html('<span style=\"color:LIMEGREEN\"><small>'+s+'</small></span>')\n",
    "    \n",
    "def print_warning(s):\n",
    "    print_html('<span style=\"color:LIGHTSALMON\"><small>'+s+'</small></span>')\n",
    "\n",
    "## Plenty of small tools to help not creating a huge mess\n",
    "\n",
    "def global_pandas_store_file_name(file_name,ext='.pkl'):\n",
    "    return PANDAS_STORE +'/'+file_name+ext\n",
    "\n",
    "def local_pandas_store_file_name(file_name):\n",
    "    return env_file_name(file_name,PICKLE_EXTENSION)\n",
    "\n",
    "def env_path():\n",
    "    return '../'+EXPERIMENT\n",
    "\n",
    "def env_file_name(file_name,ext=''):\n",
    "    return env_path()+'/'+file_name+ext\n",
    "\n",
    "def absolute_env_file_name(file_name,ext=''):\n",
    "    return str(os.path.abspath(env_path()+'/'+file_name+ext))\n",
    "\n",
    "def copy_from_pandas_store_if_missing(file_name):\n",
    "    if not os.path.exists(env_file_name(file_name)):\n",
    "        print_info('Make local copy of %s' % global_pandas_store_file_name(file_name))\n",
    "        copyfile(global_pandas_store_file_name(file_name),local_pandas_store_file_name(file_name))\n",
    "\n",
    "def prepare_environnement():\n",
    "    print_section('Prepare %s environment' % EXPERIMENT)\n",
    "    # with recent versions use tqdm.pandas(desc=\"my bar!\")\n",
    "    # tqdm_pandas(tqdm())\n",
    "    tqdm.pandas()\n",
    "    if not os.path.exists(env_path()):\n",
    "        os.mkdir(env_path())\n",
    "    copy_from_pandas_store_if_missing(CLEAN_TRAINING_DATA)\n",
    "    copy_from_pandas_store_if_missing(CLEAN_CHALLENGE_DATA)\n",
    "    print_done('Done')\n",
    "    print\n",
    "\n",
    "## Tools to cache important and costly data\n",
    "\n",
    "def load_dataframe(file_name):\n",
    "    df = pandas.read_pickle(local_pandas_store_file_name(file_name))\n",
    "    return df\n",
    "\n",
    "def save_dataframe(df,file_name):\n",
    "    print_info('Save %s' % file_name )\n",
    "    df.to_pickle(local_pandas_store_file_name(file_name))\n",
    "\n",
    "def load_or_build_dataframe(dataframe_name,file_name,builder,dataframe):\n",
    "    print_section('%s: Load or rebuild %s' % (dataframe_name,file_name))\n",
    "    if os.path.exists(local_pandas_store_file_name(file_name)):\n",
    "        print_info(\"!!!!! %s is cached!!!\" % local_pandas_store_file_name(file_name))\n",
    "        df = load_dataframe(file_name)\n",
    "    else:\n",
    "        print_warning(\"!!!!! %s does not exists!!!\" % local_pandas_store_file_name(file_name))\n",
    "        print_warning('Rebuild and save it')\n",
    "        df = builder(dataframe)\n",
    "        save_dataframe(df,file_name)\n",
    "    print_done('Done:%s contains %d lines' % (file_name,len(df)))\n",
    "    return df\n",
    "\n",
    "# Code to generate all combination of numeric features\n",
    "from itertools import compress, product\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def all_numeric_columns(dataframe):\n",
    "    l = list()\n",
    "    for name in dataframe.columns:\n",
    "        if dataframe.dtypes[name] in ['int64','float64'] and name not in ['test_id','id','qid1','qid2','is_duplicate']:\n",
    "            l.append( name)\n",
    "    return l\n",
    "\n",
    "def all_float_columns(dataframe):\n",
    "    l = list()\n",
    "    for name in dataframe.columns:\n",
    "        if dataframe.dtypes[name] in ['float64']:\n",
    "            l.append( name)\n",
    "    return l\n",
    "\n",
    "def all_subsets(ss):\n",
    "    return list(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))))\n",
    "\n",
    "def clean_combination_name(c):\n",
    "    return str(numpy.asarray(c)).replace(\"' '\",\"+\").replace(\"['\",\"\").replace(\"']\",\"\").replace(\"'\",\"\").replace(\" \",\"\").replace('\\n','+')\n",
    "\n",
    "def clean_all_combination_names(dataframe):\n",
    "    for c in all_subsets(all_numeric_columns(dataframe)):\n",
    "        if len(c)>0:\n",
    "            print('|%s|'% clean_combination_name(c))\n",
    "\n",
    "#print( 'All numeric columns\\n%s' % all_numeric_columns(train_dataframe))\n",
    "#print('All combinations of numeric columns\\n %d combinations\\n' % len(all_subsets(all_numeric_columns(train_dataframe))))\n",
    "#for c in all_subsets(all_numeric_columns(train_dataframe)):\n",
    "#    print(c)\n",
    "#clean_all_combination_names(train_dataframe)\n",
    "#print( '%d combination of features will be studied' % (len(list(all_subsets(all_numeric_columns(train_dataframe))))-1))\n",
    "\n",
    "# code to put plots in a grid\n",
    "\n",
    "def multiplot_from_generator(g, num_columns, figsize_for_one_row=None):\n",
    "    # call 'next(g)' to get past the first 'yield'\n",
    "    next(g)\n",
    "    # default to 15-inch rows, with square subplots\n",
    "    if figsize_for_one_row is None:\n",
    "        figsize_for_one_row = (15, 15/num_columns)\n",
    "    try:\n",
    "        while True:\n",
    "            # call plt.figure once per row\n",
    "            plot.figure(figsize=figsize_for_one_row)\n",
    "            for col in range(num_columns):\n",
    "                ax = plot.subplot(1, num_columns, col+1)\n",
    "                next(g)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "# apply tools\n",
    "def apply_file_name(criteria,kind,model_key,ext='.csv'):\n",
    "    return env_file_name(SEP_IN_FILE_NAME.join((EXPERIMENT,criteria,kind,clean_combination_name(model_key).replace('/','_div_'))),ext=ext)\n",
    "\n",
    "def apply_absolute_file_name(criteria,kind,model_key,ext='.csv'):\n",
    "    return str(os.path.abspath(apply_file_name(criteria,kind,model_key,ext=ext)))\n",
    "\n",
    "# Zip tools\n",
    "from zipfile import ZipFile,ZIP_DEFLATED \n",
    "import zlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def zip_file_name(original_file_name):\n",
    "    return str(Path(original_file_name).with_suffix('.zip'))\n",
    "\n",
    "def zip_file_and_delete(original_file_name):\n",
    "    zip_name = zip_file_name(original_file_name) \n",
    "    zip = ZipFile(str(zip_name), 'w',compression=ZIP_DEFLATED)\n",
    "    zip.write(original_file_name)\n",
    "    zip.close()\n",
    "    os.unlink(original_file_name)\n",
    "    return zip_name\n",
    "\n",
    "# Excel tools\n",
    "def excel_file_name(file_name):\n",
    "    return env_file_name(file_name,ext='.xlsx')\n",
    "\n",
    "def pandas_to_excel(dataframe,file_name):\n",
    "    dataframe.to_excel(excel_file_name(SEP_IN_FILE_NAME.join([EXPERIMENT,file_name])),float_format=EXCEL_PRECISION)\n",
    "\n",
    "def save_models_dict_to_excel(models_dict,file_name='all_models'):\n",
    "    results = models_dict_to_models_results(models_dict)\n",
    "    results.to_excel(excel_file_name('_'.join([EXPERIMENT,file_name])),float_format=\"%.4f\")\n",
    "\n",
    "# Kaggle submissions tool\n",
    "import subprocess\n",
    "\n",
    "def load_kaggle_submissions():\n",
    "    print_section('Load all Kaggle submissions')\n",
    "    generic_submissions_name = EXPERIMENT+'_submissions'\n",
    "    file_name_csv = absolute_env_file_name(generic_submissions_name,ext='.csv')\n",
    "    file_name_excel = absolute_env_file_name(excel_file_name(generic_submissions_name))\n",
    "    csv_output = open(file_name_csv,\"w\")\n",
    "    proc = subprocess.Popen(KAGGLE_GET_SUBMISSIONS_COMMAND.split(),stdout=csv_output)\n",
    "    proc.wait()\n",
    "    csv_output.close()\n",
    "    print_info('All submissions are available in .csv&nbsp;&nbsp;format with %s' % file_name_csv)\n",
    "    submissions = pandas.read_csv(file_name_csv,error_bad_lines=True,warn_bad_lines=True)\n",
    "    # fix dataframe so it is more convenient to use\n",
    "    #submissions = submissions[submissions['status']=='complete' & submissions['description']!='first xgboost']\n",
    "    submissions = submissions[submissions['status']=='complete']\n",
    "    submissions = submissions[['date','publicScore','privateScore','description','fileName']]\n",
    "    submissions['date'] = pandas.to_datetime(submissions['date'])\n",
    "    submissions['publicScore'] = submissions['publicScore'].astype('float64')\n",
    "    submissions['privateScore'] = submissions['privateScore'].astype('float64')\n",
    "    submissions.to_excel(file_name_excel,float_format=\"%.4f\")\n",
    "    print_info('All submissions are available in .xlsx format with %s' % file_name_excel)\n",
    "    return submissions\n",
    "\n",
    "def show_last_submissions(submissions,n=3):\n",
    "    return submissions.nlargest(n,'date')\n",
    "\n",
    "def put_first(l,e):\n",
    "    l.insert(0,e)\n",
    "    return list(dict.fromkeys(l))\n",
    "\n",
    "\n",
    "def show_best_submissions(submissions,n=3,metric='publicScore',):\n",
    "    return submissions.nsmallest(n,metric)[put_first(submissions.columns.values.tolist(),metric)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<b>Prepare universal_sentence_similarity_lite environment</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>Make local copy of ../PandasStore/clean_training.pkl</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:LIMEGREEN\"><small>Make local copy of ../PandasStore/clean_challenge.pkl</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:LIMEGREEN\"><small><b><i>Done</i></b><p></p></small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    }
   ],
   "source": [
    "prepare_environnement()\n",
    "train_dataframe=load_dataframe(CLEAN_TRAINING_DATA)\n",
    "challenge_dataframe=load_dataframe(CLEAN_CHALLENGE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /root/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.compat.v1 as tf\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\nSentencePiece model loaded at b'/tmp/tfhub_modules/539544f0a997d91c327c23285ea00c37588d92cc/assets/universal_encoder_8k_spm.model'.\n"
    }
   ],
   "source": [
    "module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\")\n",
    "input_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None])\n",
    "encodings = module(\n",
    "    inputs=dict(\n",
    "        values=input_placeholder.values,\n",
    "        indices=input_placeholder.indices,\n",
    "        dense_shape=input_placeholder.dense_shape))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    spm_path = sess.run(module(signature=\"spm_path\"))\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(spm_path)\n",
    "print(\"SentencePiece model loaded at {}.\".format(spm_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_to_IDs_in_sparse_format(sp, sentences):\n",
    "  # An utility method that processes sentences with the sentence piece processor\n",
    "  # 'sp' and returns the results in tf.SparseTensor-similar format:\n",
    "  # (values, indices, dense_shape)\n",
    "  ids = [sp.EncodeAsIds(x) for x in sentences]\n",
    "  max_len = max(len(x) for x in ids)\n",
    "  dense_shape=(len(ids), max_len)\n",
    "  values=[item for sublist in ids for item in sublist]\n",
    "  indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n",
    "  return (values, indices, dense_shape)\n",
    "\n",
    "\n",
    "def compute_distance(sp, session,q1, q2):\n",
    "  ids = [sp.EncodeAsIds(q1),sp.EncodeAsIds(q2)]\n",
    "  max_len = max(len(x) for x in ids)\n",
    "  dense_shape=(len(ids), max_len)\n",
    "  values=[item for sublist in ids for item in sublist]\n",
    "  indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n",
    "  v = session.run(\n",
    "      encodings,\n",
    "      feed_dict={input_placeholder.values: values,\n",
    "                input_placeholder.indices: indices,\n",
    "                input_placeholder.dense_shape: dense_shape})\n",
    "  try:\n",
    "      return distance.euclidean(v[0],v[1])\n",
    "  except:\n",
    "      return 1000000.0\n",
    "\n",
    "\n",
    "def add_column_from_columns(dataframe,output_column_name,function):\n",
    "    dataframe[output_column_name]=dataframe.progress_apply(function,axis=1)\n",
    "    return dataframe[output_column_name]\n",
    "\n",
    "from scipy.spatial import distance\n",
    "def build_all_similarities(dataframe):\n",
    "    add_column_from_columns(dataframe,'universal_sentence_similarity',lambda r: compute_distance(sp,session,r.question1,r.question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<b>Challenge universal sentence similarity: Load or rebuild challenge_universal_sentence_similarity</b>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<HR>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>!!!!! ../universal_sentence_similarity_lite/challenge_universal_sentence_similarity.pkl does not exists!!!</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:LIGHTSALMON\"><small>Rebuild and save it</small></span>"
     },
     "metadata": {
      "text/html": {
       "isolated": true
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2345796.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "556237bdc4c9441cb6f4bc208483d059"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6fd201ee8b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchallenge_dataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_or_build_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Challenge universal sentence similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'challenge_universal_sentence_similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_all_similarities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchallenge_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_or_build_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training universal sentence similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'training_universal_sentence_similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild_all_similarities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b4fbd65dfcef>\u001b[0m in \u001b[0;36mload_or_build_dataframe\u001b[0;34m(dataframe_name, file_name, builder, dataframe)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!!!!! %s does not exists!!!\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlocal_pandas_store_file_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mprint_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rebuild and save it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0msave_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mprint_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done:%s contains %d lines'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5780c7923a82>\u001b[0m in \u001b[0;36mbuild_all_similarities\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_all_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0madd_column_from_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'universal_sentence_similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompute_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5780c7923a82>\u001b[0m in \u001b[0;36madd_column_from_columns\u001b[0;34m(dataframe, output_column_name, function)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_column_from_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_column_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5780c7923a82>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_all_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0madd_column_from_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'universal_sentence_similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompute_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5780c7923a82>\u001b[0m in \u001b[0;36mcompute_distance\u001b[0;34m(sp, session, q1, q2)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   v = session.run(\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       feed_dict={input_placeholder.values: values,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1359\u001b[0m                            run_metadata)\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1439\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1440\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1441\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "challenge_dataframe=load_or_build_dataframe('Challenge universal sentence similarity','challenge_universal_sentence_similarity',build_all_similarities,challenge_dataframe)\n",
    "train_dataframe=load_or_build_dataframe('Training universal sentence similarity','training_universal_sentence_similarity',build_all_similarities,train_dataframe)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}